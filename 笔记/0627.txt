1.主机ping不通虚拟机
	虚拟机要设置IP地址，ip段是vmware
	编辑菜单-->虚拟网络编辑器 网段，
	网关：192.168.xxx.2
	ip地址不要是.1/.2
	把vmware装好以后，在“网络适配器”里应该多出两个适配器
2.linux
	使用linux里的一些命令
	cd:切换目录
	tar -zxvf ....tar.gz，对tar文件进行解压
	su[用户名] 不写用户名，默认切换到root用户
	vi文件名称。刚进入的时候是命令模式
		输入i，进入insert模式
		编辑完成后，按esc退出insert模式
		：wq 保存退出
		：q   只退出
		：q！ 强制退出
用户机制
	root用户，超级用户，对整个linux系统有完全的权限
		一般不使用这个用户，这个用户权限太大了
	普通用户，有一定的权限
		一般可以操作自己家目录和/tmp目录
		/home/用户名
	linux权限
		ll命令查看文件的时候
		drwxr-xr-x. 2h hadoop hadoop 4096 jun 26  23:06 bin
			drwxr-xr-x:10个字符
				第一个字符表示文件的类型，-代表是文件。d是目录
				后面9个字符分为了3组，每组3个字符
				第一组（文件所有者的权限信息）：rwx，r可读，w可写，x可执行
				第二组（文件所有者的同一组其他用户的权限信息）
				第三者：其他用户的权限信息
	
	linux的文件系统
		和window是不一样，没有盘符的概念
		只有一个根目录 /
			/root root用户的家目录
	ssh免密码登陆：rsa加密方式，会生成一个公钥和私钥
		配置的时候，把公钥发送个受信任主机
		A主机     B主机
		A把自己的公钥发送个B，A就可以免密登陆B
格式化出错
	配置文件有问题
进程少一个
	namenode 一般来说hosts文件没有配置
	ping 主机名
重启后进程少了
	/tmp里和hadoop相关的文件被删除
	
	
格式化操作
	bin/hdfs namenode -format操作生成了一些格式化信息
	默认在/tep/hadoop-用户名/dfs/name/current/VEPSION
	如需再次格式化需要把上面的信息删除
	
	因为格式化信息没入是在/tmp，该目录里的文件可能被linux系统删除
	把HDFS的储存信息放到一个安全地方
	在hdfs-site.xml文件里设置
		<property>
			<name>dfs.name.dir</name>
			<value>/home/hadoop/appData/hadoop/name</value>
		</property>
		<property>
			<name>dfs.data.dir</name>
			<value>/home/hadoop/appData/hadoop/data</value>
		</property>
	重新格式化
	
	Hadoop核心
		common
		分布式存储（HDFS）
		分布式计算（MapReduce）
		YARN资源管理
		
	云计算
		把底层的物理奖的所有资源（CPU，内存，硬盘等）进行汇总
		然后再这个大的资源池中，创建虚拟机
		
	例如：你做了一个web网站、图片，把图片进行存储
		192.168.85.111/pic/ssss.jpg
		随着时间的推移，图片容量会越来越大。111这个服务器不够用了
		192.168.85.112/pic/ssss.jpg
		192.168.85.113/pic/ssss.jpg
		192.168.85.114/pic/ssss.jpg
		
		图片需要被调用，通过图片路径来调用
		当一台服务器的时候：192.168.85.111/pic/ssss.jpg
		当多台服务器的时候，想要显示一张图片，需要遍历各个服务器增加实现难度，文件的可靠性
		
		hadoop已经很好的解决了上面的问题
			HDFS，hadoop分布式文件系统
				它的文件系统，和linux文件系统类似，都是从/根目录开始的
			
			/pic/a.jpg，给用户的接口
			但是文件是存储在hadoop集群中的
			如：a,b,c,d,e节点，a.jpg可能存储在a节点，可能存储在b节点


	HDFS是一个主从结构，主节点叫做NameNode（NN）从节点叫做DataNode（DN）
	
	分布式部署
		非HA
		HA：在2.0以后有了官方的支持
Hadoop web接口。http://192.168.152.4:50070
	关闭防火墙 root用户 /etc/init.d/iptables stop
	root用于：service iptables stop

Blocks:数据块，hadoop要存容量比较大的文件
	一个文件200G，读取该文件，如果文件有错了怎么办，
	校验和，一般在文件传输的时候，都需要有校验和
	
	如果校验和在传输的时候出错了怎么办？
		重新传输该文件，但是如果文件比较大，时间代价也很大。
		把文件进行切块传输。
	
	hadoop里的数据块大小，默认是128M（2.X）

Replication Factor（复制因子）：在hdfs-site.xml文件中进行配置，默认是3
	文件在hadoop备份的数量
	
NameNode在内存中存储集群的元数据
	元数据：
		文件的类型，权限
		文件块的信息
		数据节点的信息等
		
fsimage：集群的镜像文件，存储了集群的元数据

edits：保存对文件系统的修改（元数据）

fsimage:和edits文件都是存储元数据，有什么区别。
	随着集群的使用，元数据会越来越多，1M--100M--1G--10G
	当元数据是1M的时候，写数据很快
	当元数据达到10G的时候，想写数据没那么容易
edits每次对集群修改的时候，先把元数据写道edits文件中，
	等到达一定条件时（时间，文件大小），再把edits和fsimage文件进行合并

HDFS文件系统和linux文件系统比较类型
	HDFS文件系统是建立在linux文件系统之上的
	
SecondaryNameNode是NameNode的一个备用，但是在NN失效后，	SecondaryNameNode不能代替NN
		SecondaryNameNode主要作用是把fsimage和edits文件进行合并
		
NN要恢复，需要fsimage和edits文件，如果NN的磁盘坏了，NN会丢失数据
	因为只能使用SecondaryNameNode萝莉存储的fsimage文件。
	
退出安全模式
	bin/hdfs dfsadmin -safemode leave

DN：执行NN的指令（读文件、删除文件、添加文件）
	每隔3秒向NN发送一个心跳。告诉NN我还活着
	每隔6小时向NN报告块信息
	
	
[hadoop@localhost hadoop-2.6.0]$ bin/hadoop fs
Usage: hadoop fs [generic options]
	[-appendToFile <localsrc> ... <dst>]
	[-cat [-ignoreCrc] <src> ...]
	[-checksum <src> ...]
	[-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] <localsrc> ... <dst>]
	[-copyToLocal [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] <path> ...]
	[-cp [-f] [-p | -p[topax]] <src> ... <dst>]
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] <path> ...]
	[-expunge]
	[-get [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] <src> <localdst>]
	[-help [cmd ...]]
	[-ls [-d] [-h] [-R] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touchz <path> ...]
	[-usage [cmd ...]]

在这里的local指的是linux的文件系统
	没有加local则是HDFS的文件系统

上传文件 
	bin/hadoop fs -copyFromLocal/put localsrc dst        (要上传的文件地址  上传到的位置)
查看文件
	bin/hadoop fs -ls path
	查看的命令和显示的结果都和linux相似，这样可以降低学习hadoop的成本
查看文件内容
	bin/hadoop fs -cat path
修改文件权限
	chmod u+[rwx] 文件
	chmod 777 文件
下载文件
	bin/hadoop fs -copyToLocal/-get src localhost
创建目录
	bin/hadoop fs -mkdir /aa --创建一级目录
	bin/hadoop fs -mkdir -p /aa/bb --一次创建多级目录，增加参数-p
删除目录
    bin/hadoop fs -rmdir /aa --只能删除空目录
删除文件
	bin/hadoop fs -rm  /nottic.txt
	
	bin/hadoop fs -rm -r  /nottic.txt -r递归删除

单独启动NN进程
	nohup bin/hdfs namenode &   (nohup 后台启动)
	